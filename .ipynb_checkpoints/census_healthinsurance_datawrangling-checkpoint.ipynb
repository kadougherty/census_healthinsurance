{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1530fce7",
   "metadata": {},
   "source": [
    "## predicting the health uninsured in the US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16b5ca",
   "metadata": {},
   "source": [
    "This project will call data from the American Community Survey Public Use MicroSample(PUMS) API. The most recent survey publicly availble at this API is from 2019. (Note data from 2020 are available to download in csv files).\n",
    "\n",
    "1. American Community Survey (ACS) (census.gov).\n",
    "https://www.census.gov/programs-surveys/acs/\n",
    "2. American Community Survey Data via API (census.gov).\n",
    "https://www.census.gov/programs-surveys/acs/data/data-via-api.html\n",
    "\n",
    "The goal of this project is to predict whether an individual has health insurance (or not) based on demographic data in the PUMS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b10c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb568ed6",
   "metadata": {},
   "source": [
    "There are hundreds of variables in the PUMS dataset. Load in the variable names (code) and their descriptions (label) from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbb68293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all variable names from census PUMS (public use microsample) API\n",
    "load_dotenv()\n",
    "API_KEY  = os.getenv('CENSUS_API_KEY')\n",
    "host     = 'https://api.census.gov/data'\n",
    "year     = 2019\n",
    "dataset  = 'acs/acs1/pums/variables'\n",
    "base_url = \"/\".join([host, str(year), dataset]) \n",
    "r        = requests.get(base_url)\n",
    "rlists   = r.json()\n",
    "code     = [item[0] for item in rlists if item[0].isupper()] #code in API\n",
    "label    = [item[1].lower() for item in rlists if item[0].isupper()] # description for each code\n",
    "nsamples = 500\n",
    "\n",
    "codedict = {} # redudant with code, label but may make life easier later on\n",
    "count    = 0\n",
    "for lab in label:\n",
    "    codedict[code[count]] = lab\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d9177",
   "metadata": {},
   "source": [
    "When calling the Census API, a maximum of 50 variables can be requested at one time. The data are also easily accessed state-by-state. The PUMS represents ~1% of the population. If we want to use data from all states, we could start by subsampling from availbable records. Set the number of samples (nsamples) in getCensusDataByState().\n",
    "\n",
    "One approach is to request data from a list of variables for a specific state in one call. The function callCensusAPI() below is meant to return a dataframe with variables in 'select_codes' from one state ('stateid'). A second function, getCensusDataByState() is meant to request data for all variables for one state in multiple calls and merge that data into one single dataframe for that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba650502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get data from Census API, Public Access MicroData Samples using list of codes (max 50), state id number \n",
    "def callCensusApi(API_KEY,year,select_codes,stateid):\n",
    "    host     = 'https://api.census.gov/data'\n",
    "    dataset  = 'acs/acs1/pums'\n",
    "    query    = '?get='\n",
    "    variable = ','.join(select_codes)\n",
    "    base_url = \"/\".join([host, str(year), dataset]) + query + variable + '&for=state:' + stateid + '&key=' + API_KEY\n",
    "    callbeg  = time.time()\n",
    "    r        = requests.get(base_url) \n",
    "    colnames = variable.split(',')\n",
    "    colnames.append('state')\n",
    "    df       = pd.DataFrame(columns=colnames, data=r.json()[1:]) \n",
    "    tElapsed = time.time()-callbeg\n",
    "    return (tElapsed,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbfc0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get full dataframe (all variables in code) for one state. uses callCensusAPI function above\n",
    "def getCensusDataByState(state_id):\n",
    "    max_var_call = 50\n",
    "    start_var_n  = 0\n",
    "    end_var_n = start_var_n + max_var_call\n",
    "    totalTime = 0\n",
    "    while end_var_n <= len(code): \n",
    "        tElapsed, hdf = callCensusApi(API_KEY,year,code[start_var_n:end_var_n],state_id)\n",
    "        if start_var_n == 0:\n",
    "            df = hdf.sample(nsamples)\n",
    "            rowid = df.index\n",
    "            df = df.reset_index()\n",
    "        else:\n",
    "            sub = hdf.iloc[rowid]\n",
    "            sub = sub.reset_index()\n",
    "            df = pd.merge(df,sub,how='left',on='index')\n",
    "            del sub\n",
    "        totalTime = totalTime + tElapsed\n",
    "        start_var_n = end_var_n + 1\n",
    "        end_var_n = start_var_n + max_var_call\n",
    "    if df.shape[1] < len(code):\n",
    "        tElapsed, hdf = callCensusApi(API_KEY,year,code[start_var_n:len(code)],state_id)\n",
    "        sub = hdf.iloc[rowid]\n",
    "        sub = sub.reset_index()\n",
    "        df  = pd.merge(df,sub,how='left',on='index')      \n",
    "        totalTime = totalTime + tElapsed\n",
    "        del hdf\n",
    "    return (df,totalTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387de4c",
   "metadata": {},
   "source": [
    "With the functions above, we can loop through our states of interest and save a dataframe for each if it does not exist locally yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1abf8c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n"
     ]
    }
   ],
   "source": [
    "datadir = os.path.join(os.getcwd(),\"data\")\n",
    "try:\n",
    "    os.mkdir(datadir)\n",
    "except:\n",
    "    print('already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c8e53cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacie\\AppData\\Local\\Temp/ipykernel_33420/1824857077.py:16: FutureWarning: Passing 'suffixes' which cause duplicate columns {'state_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = pd.merge(df,sub,how='left',on='index')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3627\u001b[0m         \"\"\"\n\u001b[1;32m-> 3628\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3629\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3615\u001b[1;33m         new_data = self._mgr.take(\n\u001b[0m\u001b[0;32m   3616\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexers.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"indices are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33420/1501127615.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'state'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstate_id\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_subsample'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotalTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetCensusDataByState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m# save the data to a new csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33420/1824857077.py\u001b[0m in \u001b[0;36mgetCensusDataByState\u001b[1;34m(state_id)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrowid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m         \u001b[1;31m# a list of integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1557\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m         \u001b[1;31m# a single integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1531\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m             \u001b[1;31m# re-raise with different error message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1533\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# call API for states in loop and save csv locally if it doesn't exist yet:\n",
    "n_states = 2\n",
    "for state in range(1,n_states+1):\n",
    "    state_id  =  f\"{state:02}\"\n",
    "    fname = os.path.join(datadir,'state' + state_id + '_subsample' + str(nsamples) + '.csv')\n",
    "    if ~os.path.exists(fname):\n",
    "        df,totalTime = getCensusDataByState(state_id)\n",
    "        # save the data to a new csv file\n",
    "        df.to_csv(fname)\n",
    "        print('state' + state_id + ': ' + str(totalTime))\n",
    "    del df\n",
    "    del fname\n",
    "    del state_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aae5be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved csv files:\n",
    "filenames = glob.glob('state*subsample' + str(nsamples) +''.csv')\n",
    "data_all = pd.concat((pd.read_csv(file) for file in filenames)).reset_index(drop = True) # Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "867a6551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the subsampled dataframe: 3091 by 538\n"
     ]
    }
   ],
   "source": [
    "# check basic attributes of saved data:\n",
    "print('shape of the subsampled dataframe: ' + str(data_all.shape[0]) + ' by ' + str(data_all.shape[1]))\n",
    "print(data_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c6db519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call api for more details on a specific variable\n",
    "def variableDetails(codename):\n",
    "    base_url = \"/\".join([host, str(year), dataset, codename + '.json']) \n",
    "    r        = requests.get(base_url)\n",
    "    detail   = r.json()\n",
    "    return detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5cc07818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keeping Unnamed: 0\n",
      "keeping index\n",
      "keeping state_x\n",
      "keeping state_y\n",
      "keeping state\n",
      "(3091, 520)\n"
     ]
    }
   ],
   "source": [
    "# check for extra columns that may have appeared from the dataframe merger:\n",
    "for column in data_all:\n",
    "    if column not in codedict.keys():\n",
    "        if column.__contains__('.'):\n",
    "            data_all.drop(column,axis=1,inplace=True)\n",
    "        else:\n",
    "            print('keeping ' + column)\n",
    "\n",
    "print(data_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9548a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the way we merged state_x and state_y should be redundant\n",
    "if data_all['state_x'].equals(data_all['state_y']):\n",
    "    data_all.drop('state_y',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "115e18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the state column should be incomplete based on the way we merged, drop if it has more missing values than 'state_x'\n",
    "if data_all['state'].isna().sum() > data_all['state_x'].isna().sum():\n",
    "    data_all.drop('state',axis=1,inplace=True)\n",
    "# drop Unnamed: 0 because it's not useful at this point (from old indices)\n",
    "data_all.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fc21944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIVCOV : private health insurance coverage recode\n",
      "HICOV : health insurance coverage recode\n",
      "FHICOVP : health insurance coverage recode allocation flag\n",
      "FPRIVCOVP : private health insurance coverage recode allocation flag\n"
     ]
    }
   ],
   "source": [
    "# check for target variable (health insured or not):\n",
    "for key, value in codedict.items():\n",
    "    if value.__contains__('health insurance'):\n",
    "        print(key + \" : \" + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "94ea4202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from HICOV : \n",
      "2 : No health insurance coverage\n",
      "1 : With health insurance coverage\n",
      "from FHICOVP : \n",
      "0 : No\n",
      "1 : Yes\n"
     ]
    }
   ],
   "source": [
    "# let's check details on health insurance coverage recode, and \"...allocation flag\"\n",
    "codename = 'HICOV'\n",
    "details = variableDetails(codename)\n",
    "print('from ' + codename + ' : ')\n",
    "for key,value in details['values']['item'].items():\n",
    "    print(key, ':', value)\n",
    "\n",
    "codename = 'FHICOVP'\n",
    "print('from ' + codename + ' : ')\n",
    "details = variableDetails(codename)\n",
    "for key,value in details['values']['item'].items():\n",
    "    print(key, ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2b18c0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3091, 517)\n",
      "(3091, 516)\n"
     ]
    }
   ],
   "source": [
    "# we can drop the HICOV column, since HICOV and FHICOVP have the same info\n",
    "print(data_all.shape)\n",
    "data_all.drop('FHICOVP',axis=1,inplace=True)\n",
    "print(data_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9bfad8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTHSVCEX : other internet service\n",
      "GASP : gas cost (monthly cost, use adjhsg to adjust gasp to constant dollars)\n",
      "WGTP11 : housing weight replicate 11\n",
      "MAR : marital status\n",
      "WGTP66 : housing weight replicate 66\n",
      "FHIMRKSP : subsidized marketplace coverage allocation flag\n",
      "HINS5 : tricare or other military health care\n",
      "FMRGXP : first mortgage status allocation flag\n",
      "FES : family type and employment status\n",
      "WKL : when last worked\n",
      "WGTP33 : housing weight replicate 33\n",
      "WGTP43 : housing weight replicate 43\n",
      "WGTP59 : housing weight replicate 59\n",
      "PWGTP27 : person's weight replicate 27\n",
      "PWGTP18 : person's weight replicate 18\n",
      "AGS : sales of agriculture products (yearly sales, no adjustment factor is applied)\n",
      "PWGTP62 : person's weight replicate 62\n",
      "PWGTP52 : person's weight replicate 52\n",
      "WGTP : housing unit weight\n",
      "WGTP62 : housing weight replicate 62\n",
      "WGTP80 : housing weight replicate 80\n",
      "BDSP : number of bedrooms\n",
      "FKITP : complete kitchen facilities allocation flag\n",
      "FHINS5C : tricare coverage given through the eligibility coverage edit\n",
      "FVALP : property value allocation flag\n",
      "FHINS1P : insurance through a current or former employer or union allocation flag\n",
      "FGCLP : grandparents living with grandchildren allocation flag\n",
      "FDREMP : cognitive difficulty allocation flag\n",
      "SCIENGP : field of degree science and engineering flag - nsf definition\n"
     ]
    }
   ],
   "source": [
    "# check for missing values:\n",
    "missing_values = []\n",
    "for column in data_all:\n",
    "    missing_values.append(data_all[column].isna().sum())\n",
    "    if data_all[column].isna().sum() > 0:\n",
    "        idx = code.index(column)\n",
    "        print(code[idx] + ' : ' + label[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
